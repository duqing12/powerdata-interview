# 1.Spark提交job流程
1. 客户端client向ResouceManager提交Application，ResouceManager接受Application并根据集群资源状况选取一个node来启动Application的任务调度器driver（ApplicationMaster）
2. ResouceManager找到那个node，命令其该node上的nodeManager来启动一个新的JVM进程运行程序的driver（ApplicationMaster）部分，driver（ApplicationMaster）启动时会首先向ResourceManager注册，说明由自己来负责当前程序的运行。
3. driver（ApplicationMaster）开始下载相关jar包等各种资源，基于下载的jar等信息决定向ResourceManager申请具体的资源内容。
4. ResouceManager接受到driver（ApplicationMaster）提出的申请后，会最大化的满足资源分配请求，并发送资源的元数据信息给driver（ApplicationMaster）。
5. driver（ApplicationMaster）收到发过来的资源元数据信息后会根据元数据信息发指令给具体机器上的NodeManager，让其启动具体的container。
6. NodeManager收到driver发来的指令，启动container，conta  iner启动后必须向driver（ApplicationMaster）注册。
7. driver（ApplicationMaster）收到container的注册，开始进行任务的调度和计算，直到任务完成。
# 2.Excutor怎么获取Task
提交任务：

使用execute()方法提交一个Runnable任务给Executor。
使用submit()方法提交一个Callable任务给Executor，并返回一个Future对象，可以用于获取任务的执行结果。
获取任务：

Executor在内部维护了一个任务队列，当线程池中的线程空闲时，会从任务队列中获取任务进行执行。
# 3.Spark内存管理
- Spark内存管理
  
  在执行Spark的应用程序时，Spark集群会启动Driver和Executor两种JVM线程，前者为主控进程，负责创建Spark上下文，提交Spark作业（Job），并将作业转化为计算任务（Task），在各个Executor进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给Driver，同时为需要持久化的RDD提供存储功能。由于Driver的内存管理相对来说较为简单，本文主要对Executor的内存的管理进行分析，上下文中的Spark内存均特指Executor的内存。
- 堆内和堆外内存规划

  作为一个JVM进程，Executor的内存管理建立在JVM的内存管理之上，Spark对JVM的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark引入对外（Off-heap），使之可以直接在工作节点的系统内存中开辟空间，进一步优化内存的使用。

堆内内存受到JVM统一管理，堆外内存是直接向操作系统进行内存的申请和释放。
- 堆内内存

  堆内内存的大小，由Spark应用程序启动时spark.executor.memory参数配置。Executor内存的并发任务共享JVM堆内内存，这些任务在缓存RDD数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行Shuffle时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些Spark内部的对象实例，或者用户定义的Spark应用程序中的对象实例，均占用剩余的空间，不同的管理模式下，这三部分占用的空间大小各不同。

  Spark对堆内存的管理是一种逻辑上的规划式的管理，因为对象实例占用内存的申请和释放都是由JVM完成的，Spark只能在申请和释放前记录这些内存。

- 申请内存：

    Spark在代码中new一个对象实例JVM从堆内内存分配空间，创建对象并返回对象引用Spark保存该对象的引用，记录该对象占用的内存

- 释放内存：

    Spark记录该对象释放的内存，删除该对象的引用等待JVM的垃圾回收机制释放该对象占用的堆内内存

JVM的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行反序列化。对于Spark中序列化的对象是字节流形式的，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性的采样近似估算而得。

被Spark标记为释放的对象实例，很有可能在实际上并没有被JVM回收。导致实际可用的内存小于Spark记录的可用内存，从而无法完全避免内存溢出（OOM）的异常。

- 堆外内存

  为了进一步优化内存的使用以及提高Shuffle时排序的效率，Spark引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。

  堆外内存意味着把内存对象分配在Java虚拟机的堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机）。这样做的结果就是能保持一个较小的堆，以减少垃圾收集对应用的影响。

  利用 JDK Unsafe API（从 Spark 2.0开始，在管理堆外的存储内存时不再基于Tachyon，而是与堆外的执行内存一样， 基于JDK Unsafe API实现），Spark可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的GC扫描和回收，提升了处理性能。堆外内存可以精确的申请和释放（堆外内存之所以能够被精确的申请和释放，是由于内存的申请和释放不再通过 JVM 机制，而是直接向操作系统申请，JVM对于内存的清理是无法准确指定时间点的，因此无法实现精确的释放），而且序列化的数据占用空间可以被精确计算，所以相比与堆内内存来说降低了管理的难度，也降低了误差。

  在默认情况下堆外内存并不启用，可以通过配置spark.memory.offHeap.enabled参数启用，并由spark.memory.offHeap.size参数设定堆外空间的大小。除了没有other空间，堆外内存和堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。
### 内存空间管理
- 静态内存管理

  在Spark最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在Spark引用程序运行期间均为固定的，但用户可以引用程序启动前进行配置。

```
可用的存储内存=systemMaxMemory * spark.storge.memoryFraction * spark.storage.safetyFraction    
可用的执行内存=systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction

```
  

其中这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时Spark并没有区别对待，和其他内存一样交给了JVM去管理。

堆外的内存分配较为简单，只有存储内存和执行内存，由参数spark.memory.storageFraction决定，由于堆外内存占用空间可以被精确计算，所以无需再设定保险区域。



- 统一内存管理

Spark1.6之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对象的空间区域。

其中重要的优化在于动态占用机制，其规则如下：
  
  设定基本的存储内存和执行内存区域（spark.storage.storageFraction参数），该设定确定了双方各自拥有的空间的范围。双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间。执行内存的空间被对方占用，可以让对方占用部分转存到硬盘，然后归还借用空间。存储内存的空间被对方占用后，无法让对方归还，需要考虑shuffle过程的很多因素实现起来较为复杂。
  
  凭借统一内存管理机制，Spark在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护Spark内存的难度，但并不意味着开发者可以高枕无忧，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的RDD数据通常都是长期驻留内存的 。
### 存储内存管理
- RDD的持久化机制

  RDD作为Spark最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者由其他已有的RDD上执行转换操作产生一个新的RDD。转化后的RDD与已有的RDD之间产生依赖关系，构成了血统（Lineage）。凭借血统Spark保证了每一个RDD都可以被重新恢复。

  Task在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查Checkpoint或者按照血统重新计算。所以如果一个 RDD 上要执行多次行动，可以在第一次行动中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。 堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理。

  RDD的持久化由Spark的Storage模块负责，实现了RDD与物理存储的解耦。Storage模块负责管理Spark在计算过程中产生的数据，将那些在内存或磁盘、在本地或者远程存储数据的功能封装了起来。在具体实现时Driver端和Executor端的Storage模块构成了主从的架构，即Driver端BlackManager为Master，Executor端的BlockManager为Slave。Storage模块在逻辑上以Block为基本存储单位，RDD的每个Partition经过处理后唯一对应一个Block的（BlockId的格式为rdd_RDD-ID_PARTITION-ID）。Master负责整个Spark应用程序的Block的元数据信息的管理和维护。而Slave需要将Block的更新状态上报到Master，同时接收Master的命令，例如新增或删除一个RDD。

通过对数据结构的分析，可以看出存储级别从三个维度定义了RDD的Partition(也就是Block)的存储方式：

  - 存储位置：磁盘／堆内内存／堆外内存，如MEMORY_AND_DISK是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置。
  - 存储形式：Block缓存到存储内存后，是否为非序列化的形式。如MEMORY_ONLY是非序列化方式存储，OFF_HEAP是序列化方式存储。
  - 副本数量：大于1时需要远程冗余备份到其他节点。如DISK_ONLY_2需要远程备份1个副本。

- RDD缓存的过程

  RDD在缓存到存储内存之前，Partition中的数据一般以迭代器（Iterator）的数据结构来访问。通过迭代器可以获取分区中每一条序列化或者非序列化的数据项（Record），这些Record的对象实例在逻辑上占用了JVM堆内内存的other部分的空间，同一Partition的不同Record的空间并不连续。

  RDD在缓存到存储内存之后，Partition被转换成Block，Record在堆内或堆外存储内存中占用一块连续的空间。将Parititon由不连续的存储空间转换为连续存储空间的过程，Spark称之为展开（Unroll）。

  Block有序列化和非序列化两种存储格式，具体以哪中方式取决与该RDD的存储级别。每个Executor的Storage模块用一个链式Map结构（LinkedHashMap）来管理堆内和堆外存储内存中的所有Block对象的实例，对于这个LinkedHashMap新增和删除简介记录了内存的申请和释放。

  因为不能保证存储空间可以一次容纳Iterator中的所有数据，当前的计算任务在Unroll时要向MemeoryManager申请足够的Unroll空间来临时占位，空间不足则Unroll失败，空间足够时可以继续进行。对于序列化的Partition，其所需的Unroll空间可以直接累加计算，一次申请。而非序列化的Partition则要在遍历Record过程中依次申请，即每读取一条Record，采样估算其所需的Unroll空间进行申请，空间不足时可以中断，释放已占用的Unroll空间。

  如果最终Unroll成功，当前Partition所占用的Unroll空间被转换为正常缓存RDD的存储空间。



- 淘汰和落盘

  由于同一个Executor的所有的计算任务共享有限的存储内存空间，当有新的Block需要缓存但是剩余空间不足且无法动态占用时，就要对LinkedHashMap中的旧Block进行淘汰（Eviction），而被淘汰的Block如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（DROP），否则直接删除该Block。

存储内存的淘汰规则为：被淘汰的Block要与新Block的MemoryMode相同，即同属于堆外或者堆内内存新旧Block不能属于同一个RDD，避免循环淘汰就Block所属RDD不能处于被读状态，避免引发一致性问题遍历LinkedHashMap中Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新Block所需空间。其中LRU是LinkedHashMap的特性。

### 执行内存管理

  执行内存主要用来存储任务在执行Shuffle时占用的内存，Shuffle是按照一定规则对RDD数据重新分区的过程，我们来看Shuffle的Write和Read两个阶段对执行内存的使用：

- Shuffle Write

    若在map端选择普通的排序方式，会常用ExternalSorter进行排序，在内存中存储数据时主要占用对内执行空间。若在map端选择Tungsten的排序方式，则采用ShuffleExternalSorter直接以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。

- Shuffle Read
  
  在对reduce端的数据进行聚合时，要将数据交给Aggregator处理，在内存中存储数据时占用堆内执行空间。如果需要进行最终结果排序，则要再次将数据交给ExternalSorter处理，占用堆内执行空间。


在ExternalSorter和Aggreator中，Spark会使用一种叫AppendOnlyMap的哈希表在堆内执行内存中存储数据，但在Shuffle过程中所有数据并不能都保存该Hash表中，当这个Hash表占用的内存会进行周期性采样，当其大到一定程度，无法再从MemoryManager申请到新的执行内存时，Spark就会将其全部内容存储到磁盘文件中，这个过程被称为溢存（Spill），溢存到磁盘的文件最后被归并（Merge）。

# 4.建索引要注意哪些事情？
- 始终包含聚集索引

  当表中不包含聚集索引时，表中的数据是无序的，这会降低数据检索效率。即使通过索引缩小了数据检索的范围，但由于数据本身是无序的，当从表中提取实际数据时，会产生频繁的定位问题，这也使得SQL Server基本上不会使用无聚集索引表中的索引来检索数据。
- 保证聚集索引唯一

  由于聚集索引是非聚集索引的行定位器，如果它不唯一，则会使行定位器中包含辅助数据，同时也导致从表中提取数据时，需要借助行定位器中的辅助数据来定位，这会降低处理效率。
- 保证聚集索引最小

  每个聚集键值都是所有非聚集索引的叶结点记录，它越小，意味着每个非聚集索引的索引叶包含的有效数据越多，这对于提升索引效率很有好处。
- 覆盖索引

  覆盖索引是指索引中的列包含了数据处理中涉及的所有列，覆盖索引相当原始表的一个子集，由于这个子集中包含了数据处理涉及的所有列，因此操作这个子集就可以满足数据处理需要。一般而言，如果大多数处理都只涉及某个大表的某些列，可以考虑为这些列建立覆盖索引。
覆盖索引的建立方法是将要包含的列中的关键列做为索引键列，将其他列做为索引的包含列（使用索引创建语句中的INCLUDE子句）。
- 适量的索引

  当数据发生变化时，SQL Server会同步维护相关索引中的数据，过多的索引会加影响数据变更的处理效率。因此，只应该在经常使用的列上建立索引。
  适量的索引还体现在对索引列的组合方式的控制上。例如，如果有两个列col1和col2，这两个列的组合会产生三种使用情况：单独使用col1、单独使用col2及同时使用col1和col2。如果有为每种情况都建立索引，则需要建立三个索引。但也可以只建立一个复合索引（col1, col2），这样能够依次满足col1+col2、col1、col2这三种方式的查询，其中，col2利用这个查询会比较勉强（还要配合单独的统计），可以视实际情况确定是否需要为col2建立单独的索引。

特别注意：
不要建立重复索引，目前最常见的重复索引是单独为某个列建立主键和聚集索引

与直接从表中提取数据相比，根据索引检索数据，多了一个索引检索的过程，这个过程要求能够尽量缩小数据检索范围，并且使用最少的时间，这样才能真正保证能够通过索引提高数据检索效率。

实现上述目的，对于索引键列的选择，应该遵循如下原则：
  - 选择性原则
    
    选择性是满足条件的记录占总记录数的百分比，这个比率应该尽可能低，这样才能保证通过索引扫描后，只需要从基础表提取很少的数据。如果这个比率偏高，则不应该考虑在此列上建立索引。
  - 数据密度原则
    
    数据密度是指列值唯一的记录占总记录数的百分比，这个比率越高，则说明此列越适合建立索引。在考虑数据密度的时候，还要注意数据分布的问题，只有经常检索的密度高时，才适合建立索引。例如，如果一张表有10万记录，虽然某个列不重复的记录有9万条，但如果经常检索的2万条记录，其不重复的列值才几十条的话，这个列是不太适合建立索引的。另一种情况是，整体数据密度不大，但经常检索的数据的密度大，例如订单的状态，一般来说，订单的状态就几种，但已经Close的订单往往占整个数据的绝大部分，但数据处理的时候，基本上都是检索未Close的订单，这种情况下，为订单的状态列建立索引还是比较有效的（SQL Server 2008中，可以为这种列建立具有更佳效果的筛选索引）。
- 索引键列大小
  一般不宜为超过100Byte的列建立索引。
- 复合索引键列顺序
  在索引中，索引的顺序主要由索引中的每一个键列确定，因此，对于复合索引，索引中的列顺序是很重要的，应该优先把数据密度大，选择性列，存储空间小的列放在索引键列的前面。