# 1.wordcount的实现过程
### Map 阶段：
1. 按行读取要统计的文本文件；
2. 按空格拆分每行的单词
3. 将单词转换成 kv 键值对，格式为（单词，1）
4. 将所有的 kv 键值对中的单词按照单词首字母分区，比如分两个区，那么分区1（a-p），分区2（q-z）
### Reduce 阶段：
1. 每个 ReduceTask 拉取上一阶段所有 MapTask 的输出，按照 key 汇总
2. 对相同的 key 的 value（value 都是 1） 求和
# 2.MapReduce 与 Spark 的区别
- MapReduce 是一个分布式运算程序的编程框架。核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并行运行在一个Hadoop集群上。
- Spark 是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。
- Spark 和 Hadoop 的根本差异是多个作业之间的数据通信问题 :
  - Spark多个作业之间数据通信是基于内存，而 Hadoop 是基于磁盘。
  - Spark 只有在 shuffle 的时候将数据写入磁盘，而 Hadoop 中多个 MR 作业之间的数据交互都要依赖于磁盘交互。
  - Spark 的弹性分布式数据集（Resilient Distributed Datasets），提供了比 MapReduce 丰富的模型，可以快速在内存中对数据集进行多次迭代，MapReduce 的设计初衷并不是为了满足循环迭代式数据流处理。
  - Spark 是基于内存的，由于内存的限制，可能会由于内存资源不够导致Job执行失败，数据量大时 MapReduce 是一个更好的选择。
# 3.Spark 在 client 与在 cluster 运行的区别
- Client 模式将用于监控和调度的 Driver 模块在客户端执行，而不是在 Yarn 中，所以一般用于测试。
- Cluster模式将用于监控和调度的Driver模块启动在Yarn集群资源中执行。一般应用于实际生产环境。
# 4.相同的 SQL 在 Hive SQL 与 Spark SQL 的实现中，为什么 Spark 比 Hadoop 快
- Hive 的底层时 MapReduce，所以比 Spark 慢
# 5.UDF 是什么
- UDF（User-Defined Functions）是用户定义的 hive 函数。
- UDF：one to one，一进一出，如：upper、substr函数
- UDAF：many to one，多进一出，如：sum、min。
- UDTF：one to many ，一进多出。如：alteral view 与 explode
# 6.设计 HBase 表需要注意的点
- Hbase 中一条数据的唯一标识就是rowkey，那么这条数据存储于哪个分区，取决于rowkey处于哪个一个预分区的区间内，设计 rowkey的主要目的 ，就是让数据均匀的分布于所有的 region 中，在一定程度上防止数据倾斜。常用方法：
  - 生成随机数、hash、散列值。比如：原本 rowKey 为1001的哈希后变成:dd01903921ea24941c26a48f2cec24e0bb0e8cc7
  - 字符串反转:20170524000001转成10000042507102，20170524000002转成20000042507102
  - 字符串拼接:20170524000001_a12e，20170524000001_93i7
# 7.HBase的 Hlog
### Hlog简介
- Hlog是Hbase实现WAL（Write ahead log）方式产生的日志信息，内部是一个简单的顺序日志。每个RegionServer对应1个Hlog(备注：1.x版本的可以开启MultiWAL功能，允许多个Hlog)，所有对于该RegionServer的写入都被记录到Hlog中。Hlog实现的功能就是我们前面讲到的保证数据安全。当RegionServer出现问题的时候，能跟进Hlog来做数据恢复。此外为了保证恢复的效率，Hbase会限制最大保存的Hlog数量，如果达到Hlog的最大个数（hase.regionserver.max.logs参数控制）的时候，就会触发强制刷盘操作。对于已经刷盘的数据，其对应的Hlog会有一个过期的概念，Hlog过期后，会被监控线程移动到.oldlogs，然后会被自动删除掉。
### Hlog结构
- 都个Region共享一个Hlog文件，
- 单个Region在Hlog中是按照时间顺序存储的，
- 但是多个Region可能并不是完全按照时间顺序
- 每个Hlog最小单元由Hlogkey和WALEdit两部分组成。Hlogky由sequenceid、timestamp、cluster ids、regionname以及tablename等组成，WALEdit是由一系列的KeyValue组成，对一行上所有列（即所有KeyValue）的更新操作，都包含在同一个WALEdit对象中，这主要是为了实现写入一行多个列时的原子性。
```
    Hlog
        Hlogkey
            sequenceid ： 一个store级别的自增序列号，region的数据恢复和Hlog过期清除都要依赖这个信息
            timestamp
            cluster ids
            regionname
            tablename
        WALEdit
            n个 KeyValue
```
- sequenceid的相关逻辑：Memstore在达到一定的条件会触发刷盘的操作，刷盘的时候会获取刷新到最新的一个sequenceid的下一个sequenceid，并将新的sequenceid赋给oldestUnflushedSequenceId，并刷到Ffile中。
- Hlog文件对应所有Region的store中最大的sequenceid如果已经刷盘，就认为Hlog文件已经过期，就会移动到.oldlogs，等待被移除
- 当RegionServer出现故障的时候，需要对Hlog进行回放来恢复数据。回放的时候会读取Hfile的oldestUnflushedSequenceId中的sequenceid和Hlog中的sequenceid进行比较，小于sequenceid的就直接忽略，但与或者等于的就进行重做。回放完成后，就完成了数据的恢复工作
### Hlog的生命周期
- 产生:所有涉及到数据的变更都会先写Hlog，除非是你关闭了Hlog
- 滚动:Hlog的大小通过参数hbase.regionserver.logroll.period控制，默认是1个小时，时间达到hbase.regionserver.logroll.period 设置的时间，Hbase会创建一个新的Hlog文件。这就实现了Hlog滚动的目的。Hbase通过hbase.regionserver.maxlogs参数控制Hlog的个数。滚动的目的，为了控制单个Hlog文件过大的情况，方便后续的过期和删除。
- 过期:Hlog的过期判断依赖于sequenceid。Hbase会将Hlog的sequenceid和Hfile最大的sequenceid（刷新到的最新位置）进行比较，如果该Hlog文件中的sequenceid比刷新的最新位置的sequenceid都要小，那么这个Hlog就过期了，过期了以后，对应Hlog会被移动到.oldlogs目录。
- 要将过期的Hlog移动到.oldlogs目录，而不是直接删除，原因如下：
  - 因为Hbase还有一个主从同步的功能，这个依赖Hlog来同步Hbase的变更，有一种情况不能删除Hlog，那就是Hlog虽然过期，但是对应的Hlog并没有同步完成，因此比较好的做好是移动到别的目录。再增加对应的检查和保留时间。
删除
  - 如果Hbase开启了replication，当replication执行完一个Hlog的时候，会删除Zoopkeeper上的对应Hlog节点。在Hlog被移动到.oldlogs目录后，Hbase每隔hbase.master.cleaner.interval（默认60秒）时间会去检查.oldlogs目录下的所有Hlog，确认对应的Zookeeper的Hlog节点是否被删除，如果Zookeeper 上不存在对应的Hlog节点，那么就直接删除对应的Hlog。
  - hbase.master.logcleaner.ttl（默认10分钟）这个参数设置Hlog在.oldlogs目录保留的最长时间。
# 8.数据同样存在 HDFS，为什么 HBase 支持在线查询
- HBase 划分了多个 region，例如 1TB 分 500 个，那么最多只用读 2GB
- 列式存储：例如 region 分了 3 个列簇，那么 2GB / 3 = 666M，一个列簇有分为多个 HStoreFile，假如一个是 128M，总共有 6 个，一个在内存，剩下 5 个在磁盘
- 排序：记录排好序的，平均只需要遍历一半即 2.5 个 HStoreFile 共 300M
- kv 存储：只需要遍历 key 的位置就能判断
- 实时查询就是从内存中查询，HBase 数据先写入内存，达到一定的量再写入磁盘，在内存中只增加数据，用户的操作在内存中完成，保证实时响应。
# 9.Spark Streaming与 Flink与什么区别
- Flink 是标准的实时处理引擎，基于事件驱动。Spark Streaming 是微批（Micro-Batch）的模型。
- 时间机制：Spark Streaming 支持的时间机制有限，只支持处理时间。 Flink 支持了流处理程序在时间上的三个定义：处理时间、事件时间、注入时间。同时也支持 watermark 机制来处理滞后数据。
- 容错机制对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰好一次处理语义。Flink 则使用两阶段提交协议来解决这个问题。
# 10.有三个map，一个reduce来做top10，哪种方法最优。数据量特别大。
- 直接在 Reduce 中排序。
- 定义一个 size = 10 的小顶堆，大于堆顶元素才入堆。
- 利用 MapReduce 的高级 API 编程，定义分区器和分组比较器。